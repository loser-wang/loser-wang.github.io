<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Docker部署Kafka集群 | Gridea</title>
<link rel="shortcut icon" href="https://loser-wang.github.io/favicon.ico?v=1673338698301">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://loser-wang.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Docker部署Kafka集群 | Gridea - Atom Feed" href="https://loser-wang.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="1. 自己打包部署
1.1 Docker部署单机Kafka
部署代码
目录结构:
./
├── dockerfile
├── kafka_2.12
├── run.sh
└── sources.list

source.list(阿里镜像)..." />
    <meta name="keywords" content="分布式" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.5.1/build/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://loser-wang.github.io">
  <img class="avatar" src="https://loser-wang.github.io/images/avatar.png?v=1673338698301" alt="">
  </a>
  <h1 class="site-title">
    Gridea
  </h1>
  <p class="site-description">
    温故而知新
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Docker部署Kafka集群
            </h2>
            <div class="post-info">
              <span>
                2022-07-02
              </span>
              <span>
                9 min read
              </span>
              
                <a href="https://loser-wang.github.io/tag/YpWtC30aC/" class="post-tag">
                  # 分布式
                </a>
              
            </div>
            
              <img class="post-feature-image" src="https://loser-wang.oss-cn-beijing.aliyuncs.com/blog/logo_docker_kafka.svg" alt="">
            
            <div class="post-content-wrapper">
              <div class="post-content" v-pre>
                <h1 id="1-自己打包部署">1. 自己打包部署</h1>
<h2 id="11-docker部署单机kafka">1.1 Docker部署单机Kafka</h2>
<h3 id="部署代码">部署代码</h3>
<h4 id="目录结构">目录结构:</h4>
<pre><code class="language-shell">./
├── dockerfile
├── kafka_2.12
├── run.sh
└── sources.list
</code></pre>
<h4 id="sourcelist阿里镜像">source.list(阿里镜像)</h4>
<pre><code class="language-shell">deb http://mirrors.aliyun.com/ubuntu/ xenial main restricted
deb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted
deb http://mirrors.aliyun.com/ubuntu/ xenial universe
deb http://mirrors.aliyun.com/ubuntu/ xenial-updates universe
deb http://mirrors.aliyun.com/ubuntu/ xenial multiverse
deb http://mirrors.aliyun.com/ubuntu/ xenial-updates multiverse
deb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu xenial-security main restricted
deb http://mirrors.aliyun.com/ubuntu xenial-security universe
deb http://mirrors.aliyun.com/ubuntu xenial-security multiverse
</code></pre>
<h4 id="dockerfile">dockerfile</h4>
<pre><code class="language-java">FROM ubuntu:16.04
# 修改更改源为阿里云
COPY sources.list /etc/apt/sources.list
COPY kafka_2.12-2.8.1 /kafka_2.12-2.8.1

# 安装jdk
RUN apt-get update &amp;&amp; apt-get install -y openjdk-8-jdk --allow-unauthenticated &amp;&amp; apt-get clean all


EXPOSE 8001:9092
EXPOSE 8002:2181

# 添加启动脚本
ADD run.sh .
RUN chmod 755 run.sh
ENTRYPOINT [ &quot;/run.sh&quot; ]
</code></pre>
<h4 id="runsh">run.sh</h4>
<pre><code class="language-shell">#!/bin/bash

# 启动自带的zookeeper
cd /kafka_2.12-2.8.1
bin/zookeeper-server-start.sh config/zookeeper.properties &amp;

# 启动kafka
sleep 3
bin/kafka-server-start.sh config/server.properties &amp;

# 前台进程，防止docker闪退
top
</code></pre>
<h3 id="启动容器">启动容器</h3>
<pre><code class="language-shell">$ cd ./kafka_server_test
$ docker build -t kafka_server_test .
$ docker run -d -it kafka_server_test
$ docker exec -it 1bda5e6 bash

# 进入容器
$ jps
821 Jps
7 QuorumPeerMain
382 Kafka
</code></pre>
<h2 id="12-docker部署kafka集群">1.2 Docker部署kafka集群</h2>
<p>目录结构</p>
<pre><code class="language-shell">./mycluster
├── zookeeper-cluster
      ├── dockerfile
      ├── kafka_2.12(直接用kafka自带的zookeeper)
      ├── zookeeper-cluster.properties
      ├── run.sh
      ├── sources.list
      └── docker-compose-zookeeper.yml

├── broker-cluster
      ├── dockerfile
      ├── kafka_2.12
      ├── broker-cluster.properties
      ├── run.sh
      ├── sources.list
      └── docker-compose.yml
</code></pre>
<h3 id="创建网关mykafka-subnet">创建网关mykafka-subnet</h3>
<pre><code class="language-shell">$ docker network create --subnet 171.168.0.9/16 --gateway 171.168.0.1 mykafka-subnet
</code></pre>
<table>
<thead>
<tr>
<th>hostname</th>
<th>ip</th>
<th>port</th>
</tr>
</thead>
<tbody>
<tr>
<td>网关</td>
<td>171.168.0.1</td>
<td>port</td>
</tr>
<tr>
<td>zoo1</td>
<td>171.168.1.1</td>
<td>2184:2181</td>
</tr>
<tr>
<td>zoo2</td>
<td>171.168.1.2</td>
<td>2185:2181</td>
</tr>
<tr>
<td>zoo3</td>
<td>171.168.1.3</td>
<td>2186:2181</td>
</tr>
<tr>
<td>kafka1</td>
<td>171.168.2.1</td>
<td>9092:9092</td>
</tr>
<tr>
<td>kafka2</td>
<td>171.168.2.2</td>
<td>9093:9093</td>
</tr>
<tr>
<td>kafka3</td>
<td>171.168.2.3</td>
<td>9094:9094</td>
</tr>
</tbody>
</table>
<h3 id="zookeeper集群">Zookeeper集群</h3>
<h4 id="zookeeper-clusterproperties">zookeeper-cluster.properties</h4>
<pre><code class="language-shell">tickTime=2000
dataDir=/tmp/zookeeper
clientPort=2181
initLimit=5
syncLimit=2
</code></pre>
<h4 id="runsh-2">run.sh</h4>
<pre><code class="language-shell">#!/bin/bash

cd /kafka_2.12-2.8.1

# -------------- 1 设置集群  ---------------------
# -------------- 1.1 设置集群地址  ---------------------
string=${ZOO_SERVERS}
echo &quot; 参数: ${string}&quot;
echo &quot;---------------------------------------&quot;

# $IFS变量是LINUX系统默认变量，代表空格，制表符，换行符
# 先存储默认的$IFS变量
BAK_IFS=$IFS

#设置分隔符
IFS=&quot; &quot; 
#自动根据分隔符进行分割
arr=($string)
IFS=$BAK_IFS
echo $arr

echo &quot;------------------------------------&quot;
# Print each value of the array by using the loop
for val in ${arr[@]};
do
  echo $val &gt;&gt; ./config/zookeeper-cluster.properties
  echo $val
done

# -------------- 1.2 设置zookeeper编号  ------------------
---

mkdir /tmp/zookeeper
touch /tmp/zookeeper/myid
echo &quot;${ZOO_MY_ID}&quot; &gt;  /tmp/zookeeper/myid

echo &quot;---------------cat --------------------&quot;
cat ./config/zookeeper-cluster.properties

echo &quot;---------------cat --------------------&quot;

# -------------- 2 启动zookeeper  ---------------------

bin/zookeeper-server-start.sh /kafka_2.12-2.8.1/config/zookeeper-cluster.properties 
s 
</code></pre>
<h4 id="dockerfile-2">dockerfile</h4>
<pre><code class="language-shell">FROM ubuntu:16.04
# 修改更改源为阿里云
COPY sources.list /etc/apt/sources.list
COPY ./kafka_2.12-2.8.1 /kafka_2.12-2.8.1
COPY ./zookeeper-cluster.properties /kafka_2.12-2.8.1/config/zookeeper-cluster.properties

# 安装jdk
RUN apt-get update &amp;&amp; apt-get install -y openjdk-8-jdk --allow-unauthenticated &amp;&amp; apt-get clean all


# 添加启动脚本
ADD run.sh .
RUN chmod 755 run.sh
ENTRYPOINT [ &quot;/run.sh&quot; ]
</code></pre>
<h4 id="docker-compose-zookeeperyml">docker-compose-zookeeper.yml</h4>
<pre><code class="language-yaml">version: '3.4'

services: 
    zoo1:
        build: .
        restart: always
        hostname: zoo1
        container_name: zoo1
        ports:
            - 2184:2181
        volumes: 
            - &quot;/Users/loserwang/work/zk/data:/data&quot;
            - &quot;/Users/loserwang/work/zk/datalog:/datalog&quot;
        environment: 
            ZOO_MY_ID: 1
            ZOO_SERVERS: server.1=0.0.0.0:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888
        networks:
            kafka:
                ipv4_address: 171.168.1.1

    zoo2:
        build: .
        restart: always
        hostname: zoo2
        container_name: zoo2
        ports:
            - 2185:2181
        volumes: 
            - &quot;/Users/loserwang/work/zk/data:/data&quot;
            - &quot;/Users/loserwang/work/zk/datalog:/datalog&quot;
        environment: 
            ZOO_MY_ID: 2
            ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=0.0.0.0:2888:3888 server.3=zoo3:2888:3888
        networks:
            kafka:
                ipv4_address: 171.168.1.2

    zoo3:
        build: .
        restart: always
        hostname: zoo3
        container_name: zoo3
        ports:
            - 2186:2181
        volumes: 
            - &quot;/Users/loserwang/work/zk/data:/data&quot;
            - &quot;/Users/loserwang/work/zk/atalog:/datalog&quot;
        environment: 
            ZOO_MY_ID: 3
            ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=0.0.0.0:2888:3888
        networks:
            kafka:
                ipv4_address: 171.168.1.3

# 指定已经存在的网络
networks: 
    kafka:
        external: 
            name: mykafka-subnet 
</code></pre>
<h4 id="启动容器-2">启动容器</h4>
<pre><code class="language-shell">$ docker-compose -f docker-compose-zookeeper.yml up -d
</code></pre>
<h3 id="kafka集群">Kafka集群</h3>
<h4 id="broker-clusterproperties">broker-cluster.properties</h4>
<pre><code class="language-shell">log.dirs=/kafka/logs
</code></pre>
<h4 id="runsh-3">run.sh</h4>
<pre><code class="language-shell">#!/bin/bash


cd /kafka_2.12-2.8.1
# 设置kafka集群配置
echo &quot;broker.id=${KAFKA_BROKER_ID}&quot; &gt;&gt; ./config/broker-cluster.properties
echo &quot;zookeeper.connect=${KAFKA_ZOOKEEPER_CONNECT}&quot;  &gt;&gt; ./config/broker-cluster.properties
echp &quot;listeners=${KAFKA_LISTENERS}&quot; &gt;&gt; ./config/broker-cluster.properties


# 启动kafka
bin/kafka-server-start.sh config/broker-cluster.properties
</code></pre>
<h4 id="dockerfile-3">dockerfile</h4>
<pre><code class="language-yaml">FROM ubuntu:16.04
# 修改更改源为阿里云
COPY sources.list /etc/apt/sources.list
COPY ./kafka_2.12-2.8.1 /kafka_2.12-2.8.1
COPY ./broker-cluster.properties /kafka_2.12-2.8.1/config/broker-cluster.properties

# 安装jdk
RUN apt-get update &amp;&amp; apt-get install -y openjdk-8-jdk --allow-unauthenticated &amp;&amp; apt-get clean all


# 添加启动脚本
ADD run.sh .
RUN chmod 755 run.sh
ENTRYPOINT [ &quot;/run.sh&quot; ]
</code></pre>
<h4 id="docker-compose-kafkayml">docker-compose-kafka.yml</h4>
<pre><code class="language-yaml">version: '3.4'

services: 
    kafka1:
        build: .
        restart: always
        hostname: kafka1
        container_name: kafka1
        privileged: true
        ports:
            - 9092:9092
        environment:
              KAFKA_BROKER_ID: 1
              KAFKA_LISTENERS: PLAINTEXT://kafka1:9092
              KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2181,zoo3:2181
        volumes:
            - /Users/loserwang/work/zk/logs:/kafka
        networks:
            kafka:
                ipv4_address: 171.168.2.1
        extra_hosts: 
            zoo1: 171.168.1.1
            zoo2: 171.168.1.2
            zoo3: 171.168.1.3

    kafka2:
        build: .
        restart: always
        hostname: kafka2
        container_name: kafka2
        privileged: true
        ports:
            - 9093:9093
        environment:
              KAFKA_BROKER_ID: 2
              KAFKA_LISTENERS: PLAINTEXT://kafka2:9093
              KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2181,zoo3:2181
        volumes:
            - /Users/loserwang/work/zk/logs:/kafka
        networks:
            kafka:
                ipv4_address: 171.168.2.2
        extra_hosts: 
            zoo1: 171.168.1.1
            zoo2: 171.168.1.2
            zoo3: 171.168.1.3

    kafka3:
        build: .
        restart: always
        hostname: kafka3
        container_name: kafka3
        privileged: true
        ports:
            - 9094:9094
        environment:
              KAFKA_BROKER_ID: 3
              KAFKA_LISTENERS: PLAINTEXT://kafka3:9094
              KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2181,zoo3:2181
        volumes:
            - /Users/loserwang/work/zk/logs:/kafka
        networks:
            kafka:
                ipv4_address: 171.168.2.3
        extra_hosts: 
           zoo1: 171.168.1.1
           zoo2: 171.168.1.2
           zoo3: 171.168.1.3


networks: 
    kafka:
        external: 
            name: mykafka-subnet       
</code></pre>
<h4 id="启动容器-3">启动容器</h4>
<pre><code class="language-shell">$ docker-compose -f docker-compose-kafka.yml up -d
</code></pre>
<h3 id="验证">验证</h3>
<pre><code class="language-shell">$ ./kafka-topics.sh --create --zookeeper  localhost:2184 --replication-factor 1 --partitions 1 --topic mytest
Created topic mytest.

$ ./kafka-topics.sh --zookeeper 127.0.0.1:2185 --list
mytest
</code></pre>
<h1 id="2-官方镜像部署">2. 官方镜像部署</h1>
<p>官方说明：https://developer.confluent.io/quickstart/kafka-docker/</p>
<ol>
<li>设置：docker-compose.yml</li>
</ol>
<pre><code class="language-yaml">---
version: '3'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    ports:
      - &quot;2181:2181&quot;
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: confluentinc/cp-kafka:7.3.0
    container_name: broker
    ports:
    # To learn about configuring Kafka for access across networks see
    # https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/
      - &quot;9092:9092&quot;
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://broker:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
</code></pre>
<ol start="2">
<li>启动container:</li>
</ol>
<pre><code class="language-shell">$ docker-compose up -d
</code></pre>
<ol start="3">
<li>创建topic</li>
</ol>
<pre><code class="language-shell">$ docker exec broker \
		 kafka-topics  --bootstrap-server broker:9092 \
            			 --create \
           			   --topic quickstart
</code></pre>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li><a href="#1-%E8%87%AA%E5%B7%B1%E6%89%93%E5%8C%85%E9%83%A8%E7%BD%B2">1. 自己打包部署</a>
<ul>
<li><a href="#11-docker%E9%83%A8%E7%BD%B2%E5%8D%95%E6%9C%BAkafka">1.1 Docker部署单机Kafka</a>
<ul>
<li><a href="#%E9%83%A8%E7%BD%B2%E4%BB%A3%E7%A0%81">部署代码</a>
<ul>
<li><a href="#%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84">目录结构:</a></li>
<li><a href="#sourcelist%E9%98%BF%E9%87%8C%E9%95%9C%E5%83%8F">source.list(阿里镜像)</a></li>
<li><a href="#dockerfile">dockerfile</a></li>
<li><a href="#runsh">run.sh</a></li>
</ul>
</li>
<li><a href="#%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8">启动容器</a></li>
</ul>
</li>
<li><a href="#12-docker%E9%83%A8%E7%BD%B2kafka%E9%9B%86%E7%BE%A4">1.2 Docker部署kafka集群</a>
<ul>
<li><a href="#%E5%88%9B%E5%BB%BA%E7%BD%91%E5%85%B3mykafka-subnet">创建网关mykafka-subnet</a></li>
<li><a href="#zookeeper%E9%9B%86%E7%BE%A4">Zookeeper集群</a>
<ul>
<li><a href="#zookeeper-clusterproperties">zookeeper-cluster.properties</a></li>
<li><a href="#runsh-2">run.sh</a></li>
<li><a href="#dockerfile-2">dockerfile</a></li>
<li><a href="#docker-compose-zookeeperyml">docker-compose-zookeeper.yml</a></li>
<li><a href="#%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8-2">启动容器</a></li>
</ul>
</li>
<li><a href="#kafka%E9%9B%86%E7%BE%A4">Kafka集群</a>
<ul>
<li><a href="#broker-clusterproperties">broker-cluster.properties</a></li>
<li><a href="#runsh-3">run.sh</a></li>
<li><a href="#dockerfile-3">dockerfile</a></li>
<li><a href="#docker-compose-kafkayml">docker-compose-kafka.yml</a></li>
<li><a href="#%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8-3">启动容器</a></li>
</ul>
</li>
<li><a href="#%E9%AA%8C%E8%AF%81">验证</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#2-%E5%AE%98%E6%96%B9%E9%95%9C%E5%83%8F%E9%83%A8%E7%BD%B2">2. 官方镜像部署</a></li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://loser-wang.github.io/post/checkpoint-ji-zhi/">
              <h3 class="post-title">
                checkpoint机制
              </h3>
            </a>
          </div>
        

        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: 'da52c54f88dffc9988bf',
    clientSecret: '9dbab6c80d07d9104e3ce3651aa90c3caa4a0234',
    repo: 'loser-wang.github.io',
    owner: 'loser-wang',
    admin: ['loser-wang'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://loser-wang.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
